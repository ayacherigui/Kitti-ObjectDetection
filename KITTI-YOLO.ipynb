{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=data.yaml, epochs=50, patience=50, batch=8, imgsz=1244, save=True, cache=False, device=, workers=8, project=None, name=yolov8n_custom, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/detect/yolov8n_custom15\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.Detect                [9, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3012603 parameters, 3012587 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "WARNING ‚ö†Ô∏è --img-size [1244] must be multiple of max stride 32, updating to [1248]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/aya/Kitti-ObjectDetection/kitty/train/labels.cache... 5313 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5313/5313 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aya/Kitti-ObjectDetection/kitty/valid/labels.cache... 1513 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1513/1513 [00:00<?, ?it/s]\n",
      "Image sizes 1248 train, 1248 val\n",
      "Using 6 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/yolov8n_custom15\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50      9.84G      1.404      2.071      1.203          0       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:26<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  6.96it/s]\n",
      "                   all       1513      10350      0.503       0.39      0.373      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50      6.09G      1.296      1.353      1.156         13       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:23<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  6.85it/s]\n",
      "                   all       1513      10350      0.514      0.486      0.478      0.286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50      6.09G      1.283      1.259      1.153          9       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:20<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.16it/s]\n",
      "                   all       1513      10350      0.531      0.533      0.529      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50      6.09G      1.271      1.199      1.153         31       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:21<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:14<00:00,  6.73it/s]\n",
      "                   all       1513      10350      0.532      0.539      0.525      0.326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50      6.09G      1.243      1.117      1.138         17       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:20<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.28it/s]\n",
      "                   all       1513      10350      0.626      0.577      0.609      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50      6.09G      1.207      1.049      1.126         19       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.36it/s]\n",
      "                   all       1513      10350      0.606      0.627       0.65      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50      6.09G      1.184     0.9959      1.113         11       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:02<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.70it/s]\n",
      "                   all       1513      10350      0.687      0.616       0.67      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50      6.09G       1.16     0.9538      1.105          2       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.67it/s]\n",
      "                   all       1513      10350      0.649       0.64      0.678      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50      6.09G      1.144      0.926      1.095         16       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:01<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.66it/s]\n",
      "                   all       1513      10350      0.703      0.629        0.7      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50      6.09G      1.126     0.9004       1.09         15       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:01<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.61it/s]\n",
      "                   all       1513      10350      0.691      0.663      0.696      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50      6.09G      1.112      0.877      1.082          4       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:01<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.74it/s]\n",
      "                   all       1513      10350      0.737      0.675      0.735      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50      6.09G      1.093     0.8474      1.071         14       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.62it/s]\n",
      "                   all       1513      10350      0.749      0.693      0.738      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50      6.09G       1.08     0.8267      1.065         11       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.64it/s]\n",
      "                   all       1513      10350      0.751      0.712      0.755      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50      6.09G       1.07     0.8126      1.061         16       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.73it/s]\n",
      "                   all       1513      10350      0.778      0.696      0.764      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50      6.09G      1.063     0.8054      1.056         10       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:01<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.62it/s]\n",
      "                   all       1513      10350      0.737      0.713      0.764      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50      6.09G      1.048     0.7883      1.053         30       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:12<00:00,  2.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.39it/s]\n",
      "                   all       1513      10350      0.798      0.717      0.774      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50      6.09G      1.038     0.7749      1.047         21       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.28it/s]\n",
      "                   all       1513      10350      0.769      0.734       0.79      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50      6.09G       1.03     0.7634      1.039         13       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.31it/s]\n",
      "                   all       1513      10350      0.794      0.741      0.779      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50      6.09G      1.016      0.752      1.034         28       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.35it/s]\n",
      "                   all       1513      10350       0.76      0.744      0.792      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50      6.09G      1.006     0.7363       1.03         26       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.27it/s]\n",
      "                   all       1513      10350      0.731       0.76      0.797      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50      6.09G      1.002      0.731      1.027         22       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.40it/s]\n",
      "                   all       1513      10350      0.778      0.756      0.812      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50       6.1G     0.9948     0.7216      1.022          8       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350      0.797       0.74      0.799      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50       6.1G     0.9761     0.7058      1.012         12       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.24it/s]\n",
      "                   all       1513      10350      0.787       0.77      0.817      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50       6.1G     0.9731     0.7035      1.017          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.27it/s]\n",
      "                   all       1513      10350      0.814       0.75       0.82      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50       6.1G     0.9674     0.6956       1.01         12       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.33it/s]\n",
      "                   all       1513      10350      0.796      0.767      0.827      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50       6.1G     0.9615     0.6868      1.009          9       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.35it/s]\n",
      "                   all       1513      10350      0.769      0.788      0.822      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/50       6.1G     0.9479     0.6826      1.003         14       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.28it/s]\n",
      "                   all       1513      10350      0.802      0.772      0.825      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50       6.1G     0.9458     0.6737      1.002          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.37it/s]\n",
      "                   all       1513      10350      0.798      0.776      0.827      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50       6.1G     0.9352     0.6614     0.9973         15       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350      0.808      0.787       0.83      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50       6.1G     0.9193     0.6504     0.9911          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.34it/s]\n",
      "                   all       1513      10350      0.804       0.78      0.837      0.594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50       6.1G     0.9237     0.6528     0.9909         24       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.25it/s]\n",
      "                   all       1513      10350      0.813      0.795      0.847      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50       6.1G     0.9153     0.6434     0.9881          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.22it/s]\n",
      "                   all       1513      10350      0.803      0.805      0.844        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50       6.1G     0.9117     0.6393     0.9837         20       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.39it/s]\n",
      "                   all       1513      10350      0.837       0.78      0.841      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50       6.1G     0.9052     0.6351     0.9852         17       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350       0.83        0.8      0.852      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50       6.1G     0.8957      0.624     0.9794          8       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.22it/s]\n",
      "                   all       1513      10350      0.834      0.791      0.853      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50       6.1G     0.8944      0.627     0.9773         19       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.34it/s]\n",
      "                   all       1513      10350      0.836      0.794      0.857      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50       6.1G     0.8848     0.6108     0.9751         23       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350       0.85      0.791      0.857      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50       6.1G     0.8796     0.6071     0.9726          6       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.23it/s]\n",
      "                   all       1513      10350      0.851      0.797      0.856      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50       6.1G     0.8695     0.6014     0.9673         30       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.37it/s]\n",
      "                   all       1513      10350      0.824      0.812      0.862      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50       6.1G      0.863     0.5959     0.9662          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.18it/s]\n",
      "                   all       1513      10350      0.857      0.805      0.868      0.631\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50       6.1G     0.8702     0.5895     0.9652          9       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.27it/s]\n",
      "                   all       1513      10350       0.84      0.811       0.86      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50       6.1G     0.8579     0.5801     0.9607          2       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:05<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.37it/s]\n",
      "                   all       1513      10350      0.828      0.797      0.854      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50       6.1G     0.8491     0.5719     0.9569          5       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.23it/s]\n",
      "                   all       1513      10350      0.818      0.811      0.859      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50       6.1G     0.8365     0.5613      0.951         12       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350      0.847      0.808       0.86      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50       6.1G     0.8295     0.5553     0.9507          5       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.29it/s]\n",
      "                   all       1513      10350      0.845      0.818      0.867      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50       6.1G     0.8229     0.5488     0.9431         15       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:05<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.32it/s]\n",
      "                   all       1513      10350      0.868        0.8      0.862      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50       6.1G      0.816     0.5424     0.9423          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:06<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.24it/s]\n",
      "                   all       1513      10350      0.866      0.811       0.87      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50       6.1G     0.8074     0.5373     0.9395          6       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350      0.835      0.828       0.87      0.644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50       6.1G     0.7985     0.5311     0.9372          6       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350      0.864      0.816      0.873      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50       6.1G     0.7893     0.5215     0.9323          5       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:15<00:00,  6.21it/s]\n",
      "                   all       1513      10350      0.856      0.822      0.871      0.646\n",
      "\n",
      "50 epochs completed in 3.690 hours.\n",
      "Optimizer stripped from runs/detect/yolov8n_custom15/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/yolov8n_custom15/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/yolov8n_custom15/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "Model summary (fused): 168 layers, 3007403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:14<00:00,  6.73it/s]\n",
      "                   all       1513      10350      0.863      0.816      0.873      0.648\n",
      "               Cyclist       1513        341      0.913      0.815      0.891      0.617\n",
      "              DontCare       1513       2252      0.635      0.315      0.412      0.158\n",
      "                  Misc       1513        216       0.88       0.87       0.93      0.696\n",
      "        Person_sitting       1513         42      0.802      0.833      0.894      0.588\n",
      "                  Tram       1513         95      0.867      0.958      0.973      0.794\n",
      "                 Truck       1513        225       0.94       0.96      0.979      0.847\n",
      "                   Van       1513        581      0.931      0.924      0.963      0.798\n",
      "                   car       1513       5667      0.942      0.947      0.979      0.833\n",
      "                person       1513        931       0.86      0.724       0.84      0.497\n",
      "Speed: 0.4ms pre-process, 3.6ms inference, 0.0ms loss, 0.6ms post-process per image\n",
      "Results saved to \u001b[1mruns/detect/yolov8n_custom15\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-16 22:58:37,364 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/YOLOv8/yolov8n_custom.40d6ded8fdf64ee6b1c5320e391c8443/models/best.pt\n",
      "2023-03-16 22:58:41,756 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/YOLOv8/yolov8n_custom.40d6ded8fdf64ee6b1c5320e391c8443/models/best.pt\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    " \n",
    "# Training.\n",
    "results = model.train(\n",
    "   data='data.yaml',\n",
    "   imgsz=1244,\n",
    "   epochs=50,\n",
    "   batch=8,\n",
    "   name='yolov8n_custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "    handler._at_fork_reinit()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    self.lock._at_fork_reinit()\n",
      "AttributeError: 'NoneType' object has no attribute '_at_fork_reinit'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "Model summary (fused): 168 layers, 3007403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aya/Kitti-ObjectDetection/kitty/valid/labels.cache... 1513 i\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all       1513      10350      0.863      0.817      0.874      0.648\n",
      "               Cyclist       1513        341      0.907      0.815       0.89      0.616\n",
      "              DontCare       1513       2252      0.638      0.314      0.413      0.158\n",
      "                  Misc       1513        216      0.882       0.87       0.93      0.699\n",
      "        Person_sitting       1513         42      0.801      0.833      0.895      0.588\n",
      "                  Tram       1513         95      0.867      0.958      0.971      0.794\n",
      "                 Truck       1513        225      0.941       0.96      0.979      0.846\n",
      "                   Van       1513        581      0.931      0.924      0.963      0.801\n",
      "                   car       1513       5667      0.942      0.946      0.979      0.834\n",
      "                person       1513        931      0.862      0.727      0.844      0.495\n",
      "Speed: 0.5ms pre-process, 2.8ms inference, 0.0ms loss, 0.7ms post-process per image\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=val model=yolov8n_costum.pt data=data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aya/Kitti-ObjectDetection/kitty/valid/labels.cache... 1513 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1513/1513 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/190 [00:00<?, ?it/s]Exception ignored in: <function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "<function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "    handler._at_fork_reinit()Exception ignored in: Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "<function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    handler._at_fork_reinit()    \n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "self.lock._at_fork_reinit()  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "\n",
      "<function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>AttributeError\n",
      "        : self.lock._at_fork_reinit()handler._at_fork_reinit()'NoneType' object has no attribute '_at_fork_reinit'\n",
      "\n",
      "\n",
      "Exception ignored in: AttributeErrorTraceback (most recent call last):\n",
      ":   File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "<function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>'NoneType' object has no attribute '_at_fork_reinit'\n",
      "\n",
      "        handler._at_fork_reinit()self.lock._at_fork_reinit()\n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "AttributeError<function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>    : \n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "self.lock._at_fork_reinit()'NoneType' object has no attribute '_at_fork_reinit'\n",
      "    \n",
      "AttributeErrorhandler._at_fork_reinit()Traceback (most recent call last):\n",
      ": \n",
      "'NoneType' object has no attribute '_at_fork_reinit'  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    \n",
      "    self.lock._at_fork_reinit()handler._at_fork_reinit()\n",
      "\n",
      "AttributeError  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      ":     'NoneType' object has no attribute '_at_fork_reinit'self.lock._at_fork_reinit()\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute '_at_fork_reinit'\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 190/190 [00:14<00:00, 13.16it/s]\n",
      "                   all       1513      10350      0.863      0.817      0.874      0.648\n",
      "               Cyclist       1513        341      0.907      0.815       0.89      0.616\n",
      "              DontCare       1513       2252      0.638      0.314      0.413      0.158\n",
      "                  Misc       1513        216      0.882       0.87       0.93      0.699\n",
      "        Person_sitting       1513         42      0.801      0.833      0.895      0.588\n",
      "                  Tram       1513         95      0.867      0.958      0.971      0.794\n",
      "                 Truck       1513        225      0.941       0.96      0.979      0.846\n",
      "                   Van       1513        581      0.931      0.924      0.963      0.801\n",
      "                   car       1513       5667      0.942      0.946      0.979      0.834\n",
      "                person       1513        931      0.862      0.727      0.844      0.495\n",
      "Speed: 0.4ms pre-process, 3.4ms inference, 0.0ms loss, 0.7ms post-process per image\n"
     ]
    }
   ],
   "source": [
    "#!yolo task=detect mode=val model=\"/runs/detect/yolov8n_custom6/weights/best.pt\" data=data.yaml\n",
    "results = model.val()  # evaluate model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "    handler._at_fork_reinit()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    self.lock._at_fork_reinit()\n",
      "AttributeError: 'NoneType' object has no attribute '_at_fork_reinit'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "image 1/1 /home/aya/Kitti-ObjectDetection/kitty/train/images/000036_png.rf.04ff80c138765044b69cb8df5d4078f4.jpg: 224x640 5 cars, 1 traffic light, 10.3ms\n",
      "Speed: 0.3ms pre-process, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Before yolo\n",
    "!yolo task=detect mode=predict model=yolov8n.pt source=\"kitty/test/images/000036_png.rf.04ff80c138765044b69cb8df5d4078f4.jpg\" save=True conf=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "    handler._at_fork_reinit()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    self.lock._at_fork_reinit()\n",
      "AttributeError: 'NoneType' object has no attribute '_at_fork_reinit'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "Model summary (fused): 168 layers, 3007403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "image 1/1 /home/aya/Kitti-ObjectDetection/kitty/train/images/000036_png.rf.04ff80c138765044b69cb8df5d4078f4.jpg: 384x1248 7 cars, 9.1ms\n",
      "Speed: 0.5ms pre-process, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1248, 1248)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Try yolov8 on images\n",
    "!yolo task=detect mode=predict model=yolov8n_costum.pt source=\"kitty/test/images/000036_png.rf.04ff80c138765044b69cb8df5d4078f4.jpg\" save=True conf=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "Model summary (fused): 168 layers, 3007403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /home/aya/Desktop/Kitti-ObjectDetection/runs/detect/yolov8n_custom15/weights/best.pt with output shape (1, 13, 31941) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.1...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.5s, saved as /home/aya/Desktop/Kitti-ObjectDetection/runs/detect/yolov8n_custom15/weights/best.onnx (12.1 MB)\n",
      "\n",
      "Export complete (5.9s)\n",
      "Results saved to \u001b[1m/home/aya/Desktop/Kitti-ObjectDetection/runs/detect/yolov8n_custom15/weights\u001b[0m\n",
      "Predict:         yolo task=detect mode=predict model=/home/aya/Desktop/Kitti-ObjectDetection/runs/detect/yolov8n_custom15/weights/best.onnx -WARNING ‚ö†Ô∏è not yet supported for YOLOv8 exported models\n",
      "Validate:        yolo task=detect mode=val model=/home/aya/Desktop/Kitti-ObjectDetection/runs/detect/yolov8n_custom15/weights/best.onnx -WARNING ‚ö†Ô∏è not yet supported for YOLOv8 exported models\n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('/home/aya/Desktop/Kitti-ObjectDetection/runs/detect/yolov8n_custom15/weights/best.pt')\n",
    "# Export the model in onnx format\n",
    "model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement core (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for core\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m functional \u001b[39mas\u001b[39;00m F\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m Compose\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAddTrigger\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is the implement of BadNets [1].\n",
    "\n",
    "Reference:\n",
    "[1] Badnets: Evaluating Backdooring Attacks on Deep Neural Networks. IEEE Access 2019.\n",
    "'''\n",
    "\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "from .base import *\n",
    "\n",
    "\n",
    "class AddTrigger:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_trigger(self, img):\n",
    "        \"\"\"Add watermarked trigger to image.\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor): shape (C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Poisoned image, shape (C, H, W).\n",
    "        \"\"\"\n",
    "        return (self.weight * img + self.res).type(torch.uint8)\n",
    "\n",
    "\n",
    "class AddDatasetFolderTrigger(AddTrigger):\n",
    "    \"\"\"Add watermarked trigger to DatasetFolder images.\n",
    "\n",
    "    Args:\n",
    "        pattern (torch.Tensor): shape (C, H, W) or (H, W).\n",
    "        weight (torch.Tensor): shape (C, H, W) or (H, W).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pattern, weight):\n",
    "        super(AddDatasetFolderTrigger, self).__init__()\n",
    "\n",
    "        if pattern is None:\n",
    "            raise ValueError(\"Pattern can not be None.\")\n",
    "        else:\n",
    "            self.pattern = pattern\n",
    "            if self.pattern.dim() == 2:\n",
    "                self.pattern = self.pattern.unsqueeze(0)\n",
    "\n",
    "        if weight is None:\n",
    "            raise ValueError(\"Weight can not be None.\")\n",
    "        else:\n",
    "            self.weight = weight\n",
    "            if self.weight.dim() == 2:\n",
    "                self.weight = self.weight.unsqueeze(0)\n",
    "\n",
    "        # Accelerated calculation\n",
    "        self.res = self.weight * self.pattern\n",
    "        self.weight = 1.0 - self.weight\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"Get the poisoned image.\n",
    "\n",
    "        Args:\n",
    "            img (PIL.Image.Image | numpy.ndarray | torch.Tensor): If img is numpy.ndarray or torch.Tensor, the shape should be (H, W, C) or (H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The poisoned image.\n",
    "        \"\"\"\n",
    "\n",
    "        def add_trigger(img):\n",
    "            if img.dim() == 2:\n",
    "                img = img.unsqueeze(0)\n",
    "                img = self.add_trigger(img)\n",
    "                img = img.squeeze()\n",
    "            else:\n",
    "                img = self.add_trigger(img)\n",
    "            return img\n",
    "\n",
    "        if type(img) == PIL.Image.Image:\n",
    "            img = F.pil_to_tensor(img)\n",
    "            img = add_trigger(img)\n",
    "            # 1 x H x W\n",
    "            if img.size(0) == 1:\n",
    "                img = Image.fromarray(img.squeeze().numpy(), mode='L')\n",
    "            # 3 x H x W\n",
    "            elif img.size(0) == 3:\n",
    "                img = Image.fromarray(img.permute(1, 2, 0).numpy())\n",
    "            else:\n",
    "                raise ValueError(\"Unsupportable image shape.\")\n",
    "            return img\n",
    "        elif type(img) == np.ndarray:\n",
    "            # H x W\n",
    "            if len(img.shape) == 2:\n",
    "                img = torch.from_numpy(img)\n",
    "                img = add_trigger(img)\n",
    "                img = img.numpy()\n",
    "            # H x W x C\n",
    "            else:\n",
    "                img = torch.from_numpy(img).permute(2, 0, 1)\n",
    "                img = add_trigger(img)\n",
    "                img = img.permute(1, 2, 0).numpy()\n",
    "            return img\n",
    "        elif type(img) == torch.Tensor:\n",
    "            # H x W\n",
    "            if img.dim() == 2:\n",
    "                img = add_trigger(img)\n",
    "            # H x W x C\n",
    "            else:\n",
    "                img = img.permute(2, 0, 1)\n",
    "                img = add_trigger(img)\n",
    "                img = img.permute(1, 2, 0)\n",
    "            return img\n",
    "        else:\n",
    "            raise TypeError('img should be PIL.Image.Image or numpy.ndarray or torch.Tensor. Got {}'.format(type(img)))\n",
    "\n",
    "\n",
    "class AddMNISTTrigger(AddTrigger):\n",
    "    \"\"\"Add watermarked trigger to MNIST image.\n",
    "\n",
    "    Args:\n",
    "        pattern (None | torch.Tensor): shape (1, 28, 28) or (28, 28).\n",
    "        weight (None | torch.Tensor): shape (1, 28, 28) or (28, 28).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pattern, weight):\n",
    "        super(AddMNISTTrigger, self).__init__()\n",
    "\n",
    "        if pattern is None:\n",
    "            self.pattern = torch.zeros((1, 28, 28), dtype=torch.uint8)\n",
    "            self.pattern[0, -2, -2] = 255\n",
    "        else:\n",
    "            self.pattern = pattern\n",
    "            if self.pattern.dim() == 2:\n",
    "                self.pattern = self.pattern.unsqueeze(0)\n",
    "\n",
    "        if weight is None:\n",
    "            self.weight = torch.zeros((1, 28, 28), dtype=torch.float32)\n",
    "            self.weight[0, -2, -2] = 1.0\n",
    "        else:\n",
    "            self.weight = weight\n",
    "            if self.weight.dim() == 2:\n",
    "                self.weight = self.weight.unsqueeze(0)\n",
    "\n",
    "        # Accelerated calculation\n",
    "        self.res = self.weight * self.pattern\n",
    "        self.weight = 1.0 - self.weight\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = F.pil_to_tensor(img)\n",
    "        img = self.add_trigger(img)\n",
    "        img = img.squeeze()\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "        return img\n",
    "\n",
    "\n",
    "class AddCIFAR10Trigger(AddTrigger):\n",
    "    \"\"\"Add watermarked trigger to MNIST image.\n",
    "\n",
    "    Args:\n",
    "        pattern (None | torch.Tensor): shape (3, 32, 32) or (32, 32).\n",
    "        weight (None | torch.Tensor): shape (3, 32, 32) or (32, 32).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pattern, weight):\n",
    "        super(AddCIFAR10Trigger, self).__init__()\n",
    "\n",
    "        if pattern is None:\n",
    "            self.pattern = torch.zeros((1, 32, 32), dtype=torch.uint8)\n",
    "            self.pattern[0, -3:, -3:] = 255\n",
    "        else:\n",
    "            self.pattern = pattern\n",
    "            if self.pattern.dim() == 2:\n",
    "                self.pattern = self.pattern.unsqueeze(0)\n",
    "\n",
    "        if weight is None:\n",
    "            self.weight = torch.zeros((1, 32, 32), dtype=torch.float32)\n",
    "            self.weight[0, -3:, -3:] = 1.0\n",
    "        else:\n",
    "            self.weight = weight\n",
    "            if self.weight.dim() == 2:\n",
    "                self.weight = self.weight.unsqueeze(0)\n",
    "\n",
    "        # Accelerated calculation\n",
    "        self.res = self.weight * self.pattern\n",
    "        self.weight = 1.0 - self.weight\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = F.pil_to_tensor(img)\n",
    "        img = self.add_trigger(img)\n",
    "        img = Image.fromarray(img.permute(1, 2, 0).numpy())\n",
    "        return img\n",
    "\n",
    "\n",
    "class ModifyTarget:\n",
    "    def __init__(self, y_target):\n",
    "        self.y_target = y_target\n",
    "\n",
    "    def __call__(self, y_target):\n",
    "        return self.y_target\n",
    "\n",
    "\n",
    "class PoisonedDatasetFolder(DatasetFolder):\n",
    "    def __init__(self,\n",
    "                 benign_dataset,\n",
    "                 y_target,\n",
    "                 poisoned_rate,\n",
    "                 pattern,\n",
    "                 weight,\n",
    "                 poisoned_transform_index,\n",
    "                 poisoned_target_transform_index):\n",
    "        super(PoisonedDatasetFolder, self).__init__(\n",
    "            benign_dataset.root,\n",
    "            benign_dataset.loader,\n",
    "            benign_dataset.extensions,\n",
    "            benign_dataset.transform,\n",
    "            benign_dataset.target_transform,\n",
    "            None)\n",
    "        total_num = len(benign_dataset)\n",
    "        poisoned_num = int(total_num * poisoned_rate)\n",
    "        assert poisoned_num >= 0, 'poisoned_num should greater than or equal to zero.'\n",
    "        tmp_list = list(range(total_num))\n",
    "        random.shuffle(tmp_list)\n",
    "        self.poisoned_set = frozenset(tmp_list[:poisoned_num])\n",
    "\n",
    "        # Add trigger to images\n",
    "        if self.transform is None:\n",
    "            self.poisoned_transform = Compose([])\n",
    "        else:\n",
    "            self.poisoned_transform = copy.deepcopy(self.transform)\n",
    "        self.poisoned_transform.transforms.insert(poisoned_transform_index, AddDatasetFolderTrigger(pattern, weight))\n",
    "\n",
    "        # Modify labels\n",
    "        if self.target_transform is None:\n",
    "            self.poisoned_target_transform = Compose([])\n",
    "        else:\n",
    "            self.poisoned_target_transform = copy.deepcopy(self.target_transform)\n",
    "        self.poisoned_target_transform.transforms.insert(poisoned_target_transform_index, ModifyTarget(y_target))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (sample, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "\n",
    "        if index in self.poisoned_set:\n",
    "            sample = self.poisoned_transform(sample)\n",
    "            target = self.poisoned_target_transform(target)\n",
    "        else:\n",
    "            if self.transform is not None:\n",
    "                sample = self.transform(sample)\n",
    "            if self.target_transform is not None:\n",
    "                target = self.target_transform(target)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "\n",
    "class PoisonedMNIST(MNIST):\n",
    "    def __init__(self,\n",
    "                 benign_dataset,\n",
    "                 y_target,\n",
    "                 poisoned_rate,\n",
    "                 pattern,\n",
    "                 weight,\n",
    "                 poisoned_transform_index,\n",
    "                 poisoned_target_transform_index):\n",
    "        super(PoisonedMNIST, self).__init__(\n",
    "            benign_dataset.root,\n",
    "            benign_dataset.train,\n",
    "            benign_dataset.transform,\n",
    "            benign_dataset.target_transform,\n",
    "            download=True)\n",
    "        total_num = len(benign_dataset)\n",
    "        poisoned_num = int(total_num * poisoned_rate)\n",
    "        assert poisoned_num >= 0, 'poisoned_num should greater than or equal to zero.'\n",
    "        tmp_list = list(range(total_num))\n",
    "        random.shuffle(tmp_list)\n",
    "        self.poisoned_set = frozenset(tmp_list[:poisoned_num])\n",
    "\n",
    "        # Add trigger to images\n",
    "        if self.transform is None:\n",
    "            self.poisoned_transform = Compose([])\n",
    "        else:\n",
    "            self.poisoned_transform = copy.deepcopy(self.transform)\n",
    "        self.poisoned_transform.transforms.insert(poisoned_transform_index, AddMNISTTrigger(pattern, weight))\n",
    "\n",
    "        # Modify labels\n",
    "        if self.target_transform is None:\n",
    "            self.poisoned_target_transform = Compose([])\n",
    "        else:\n",
    "            self.poisoned_target_transform = copy.deepcopy(self.target_transform)\n",
    "        self.poisoned_target_transform.transforms.insert(poisoned_target_transform_index, ModifyTarget(y_target))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if index in self.poisoned_set:\n",
    "            img = self.poisoned_transform(img)\n",
    "            target = self.poisoned_target_transform(target)\n",
    "        else:\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            if self.target_transform is not None:\n",
    "                target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "class PoisonedCIFAR10(CIFAR10):\n",
    "    def __init__(self,\n",
    "                 benign_dataset,\n",
    "                 y_target,\n",
    "                 poisoned_rate,\n",
    "                 pattern,\n",
    "                 weight,\n",
    "                 poisoned_transform_index,\n",
    "                 poisoned_target_transform_index):\n",
    "        super(PoisonedCIFAR10, self).__init__(\n",
    "            benign_dataset.root,\n",
    "            benign_dataset.train,\n",
    "            benign_dataset.transform,\n",
    "            benign_dataset.target_transform,\n",
    "            download=True)\n",
    "        total_num = len(benign_dataset)\n",
    "        poisoned_num = int(total_num * poisoned_rate)\n",
    "        assert poisoned_num >= 0, 'poisoned_num should greater than or equal to zero.'\n",
    "        tmp_list = list(range(total_num))\n",
    "        random.shuffle(tmp_list)\n",
    "        self.poisoned_set = frozenset(tmp_list[:poisoned_num])\n",
    "\n",
    "        # Add trigger to images\n",
    "        if self.transform is None:\n",
    "            self.poisoned_transform = Compose([])\n",
    "        else:\n",
    "            self.poisoned_transform = copy.deepcopy(self.transform)\n",
    "        self.poisoned_transform.transforms.insert(poisoned_transform_index, AddCIFAR10Trigger(pattern, weight))\n",
    "\n",
    "        # Modify labels\n",
    "        if self.target_transform is None:\n",
    "            self.poisoned_target_transform = Compose([])\n",
    "        else:\n",
    "            self.poisoned_target_transform = copy.deepcopy(self.target_transform)\n",
    "        self.poisoned_target_transform.transforms.insert(poisoned_target_transform_index, ModifyTarget(y_target))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if index in self.poisoned_set:\n",
    "            img = self.poisoned_transform(img)\n",
    "            target = self.poisoned_target_transform(target)\n",
    "        else:\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            if self.target_transform is not None:\n",
    "                target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "def CreatePoisonedDataset(benign_dataset, y_target, poisoned_rate, pattern, weight, poisoned_transform_index, poisoned_target_transform_index):\n",
    "    class_name = type(benign_dataset)\n",
    "    if class_name == DatasetFolder:\n",
    "        return PoisonedDatasetFolder(benign_dataset, y_target, poisoned_rate, pattern, weight, poisoned_transform_index, poisoned_target_transform_index)\n",
    "    elif class_name == MNIST:\n",
    "        return PoisonedMNIST(benign_dataset, y_target, poisoned_rate, pattern, weight, poisoned_transform_index, poisoned_target_transform_index)\n",
    "    elif class_name == CIFAR10:\n",
    "        return PoisonedCIFAR10(benign_dataset, y_target, poisoned_rate, pattern, weight, poisoned_transform_index, poisoned_target_transform_index)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class BadNets(Base):\n",
    "    \"\"\"Construct poisoned datasets with BadNets method.\n",
    "\n",
    "    Args:\n",
    "        train_dataset (types in support_list): Benign training dataset.\n",
    "        test_dataset (types in support_list): Benign testing dataset.\n",
    "        model (torch.nn.Module): Network.\n",
    "        loss (torch.nn.Module): Loss.\n",
    "        y_target (int): N-to-1 attack target label.\n",
    "        poisoned_rate (float): Ratio of poisoned samples.\n",
    "        pattern (None | torch.Tensor): Trigger pattern, shape (C, H, W) or (H, W).\n",
    "        weight (None | torch.Tensor): Trigger pattern weight, shape (C, H, W) or (H, W).\n",
    "        poisoned_transform_train_index (int): The position index that poisoned transform will be inserted in train dataset. Default: 0.\n",
    "        poisoned_transform_test_index (int): The position index that poisoned transform will be inserted in test dataset. Default: 0.\n",
    "        poisoned_target_transform_index (int): The position that poisoned target transform will be inserted. Default: 0.\n",
    "        schedule (dict): Training or testing schedule. Default: None.\n",
    "        seed (int): Global seed for random numbers. Default: 0.\n",
    "        deterministic (bool): Sets whether PyTorch operations must use \"deterministic\" algorithms.\n",
    "            That is, algorithms which, given the same input, and when run on the same software and hardware,\n",
    "            always produce the same output. When enabled, operations will use deterministic algorithms when available,\n",
    "            and if only nondeterministic algorithms are available they will throw a RuntimeError when called. Default: False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_dataset,\n",
    "                 test_dataset,\n",
    "                 model,\n",
    "                 loss,\n",
    "                 y_target,\n",
    "                 poisoned_rate,\n",
    "                 pattern=None,\n",
    "                 weight=None,\n",
    "                 poisoned_transform_train_index=0,\n",
    "                 poisoned_transform_test_index=0,\n",
    "                 poisoned_target_transform_index=0,\n",
    "                 schedule=None,\n",
    "                 seed=0,\n",
    "                 deterministic=False):\n",
    "        assert pattern is None or (isinstance(pattern, torch.Tensor) and ((0 < pattern) & (pattern < 1)).sum() == 0), 'pattern should be None or 0-1 torch.Tensor.'\n",
    "\n",
    "        super(BadNets, self).__init__(\n",
    "            train_dataset=train_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            model=model,\n",
    "            loss=loss,\n",
    "            schedule=schedule,\n",
    "            seed=seed,\n",
    "            deterministic=deterministic)\n",
    "\n",
    "        self.poisoned_train_dataset = CreatePoisonedDataset(\n",
    "            train_dataset,\n",
    "            y_target,\n",
    "            poisoned_rate,\n",
    "            pattern,\n",
    "            weight,\n",
    "            poisoned_transform_train_index,\n",
    "            poisoned_target_transform_index)\n",
    "\n",
    "        self.poisoned_test_dataset = CreatePoisonedDataset(\n",
    "            test_dataset,\n",
    "            y_target,\n",
    "            1.0,\n",
    "            pattern,\n",
    "            weight,\n",
    "            poisoned_transform_test_index,\n",
    "            poisoned_target_transform_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
