{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=data.yaml, epochs=50, patience=50, batch=8, imgsz=1244, save=True, cache=False, device=, workers=8, project=None, name=yolov8n_custom, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/detect/yolov8n_custom15\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753067  ultralytics.nn.modules.Detect                [9, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3012603 parameters, 3012587 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "WARNING ‚ö†Ô∏è --img-size [1244] must be multiple of max stride 32, updating to [1248]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/aya/Kitti-ObjectDetection/kitty/train/labels.cache... 5313 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5313/5313 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aya/Kitti-ObjectDetection/kitty/valid/labels.cache... 1513 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1513/1513 [00:00<?, ?it/s]\n",
      "Image sizes 1248 train, 1248 val\n",
      "Using 6 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/yolov8n_custom15\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50      9.84G      1.404      2.071      1.203          0       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:26<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  6.96it/s]\n",
      "                   all       1513      10350      0.503       0.39      0.373      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50      6.09G      1.296      1.353      1.156         13       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:23<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  6.85it/s]\n",
      "                   all       1513      10350      0.514      0.486      0.478      0.286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50      6.09G      1.283      1.259      1.153          9       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:20<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.16it/s]\n",
      "                   all       1513      10350      0.531      0.533      0.529      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50      6.09G      1.271      1.199      1.153         31       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:21<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:14<00:00,  6.73it/s]\n",
      "                   all       1513      10350      0.532      0.539      0.525      0.326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50      6.09G      1.243      1.117      1.138         17       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:20<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.28it/s]\n",
      "                   all       1513      10350      0.626      0.577      0.609      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50      6.09G      1.207      1.049      1.126         19       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.36it/s]\n",
      "                   all       1513      10350      0.606      0.627       0.65      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50      6.09G      1.184     0.9959      1.113         11       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:02<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.70it/s]\n",
      "                   all       1513      10350      0.687      0.616       0.67      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50      6.09G       1.16     0.9538      1.105          2       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:00<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.67it/s]\n",
      "                   all       1513      10350      0.649       0.64      0.678      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50      6.09G      1.144      0.926      1.095         16       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:01<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.66it/s]\n",
      "                   all       1513      10350      0.703      0.629        0.7      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50      6.09G      1.126     0.9004       1.09         15       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:01<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.61it/s]\n",
      "                   all       1513      10350      0.691      0.663      0.696      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50      6.09G      1.112      0.877      1.082          4       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:01<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.74it/s]\n",
      "                   all       1513      10350      0.737      0.675      0.735      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50      6.09G      1.093     0.8474      1.071         14       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.62it/s]\n",
      "                   all       1513      10350      0.749      0.693      0.738      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50      6.09G       1.08     0.8267      1.065         11       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.64it/s]\n",
      "                   all       1513      10350      0.751      0.712      0.755      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50      6.09G       1.07     0.8126      1.061         16       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:00<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.73it/s]\n",
      "                   all       1513      10350      0.778      0.696      0.764      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50      6.09G      1.063     0.8054      1.056         10       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:01<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.62it/s]\n",
      "                   all       1513      10350      0.737      0.713      0.764      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50      6.09G      1.048     0.7883      1.053         30       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:12<00:00,  2.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.39it/s]\n",
      "                   all       1513      10350      0.798      0.717      0.774      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50      6.09G      1.038     0.7749      1.047         21       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.28it/s]\n",
      "                   all       1513      10350      0.769      0.734       0.79      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50      6.09G       1.03     0.7634      1.039         13       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.31it/s]\n",
      "                   all       1513      10350      0.794      0.741      0.779      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50      6.09G      1.016      0.752      1.034         28       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.35it/s]\n",
      "                   all       1513      10350       0.76      0.744      0.792      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50      6.09G      1.006     0.7363       1.03         26       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.27it/s]\n",
      "                   all       1513      10350      0.731       0.76      0.797      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50      6.09G      1.002      0.731      1.027         22       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.40it/s]\n",
      "                   all       1513      10350      0.778      0.756      0.812      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50       6.1G     0.9948     0.7216      1.022          8       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350      0.797       0.74      0.799      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50       6.1G     0.9761     0.7058      1.012         12       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.24it/s]\n",
      "                   all       1513      10350      0.787       0.77      0.817      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50       6.1G     0.9731     0.7035      1.017          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.27it/s]\n",
      "                   all       1513      10350      0.814       0.75       0.82      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50       6.1G     0.9674     0.6956       1.01         12       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.33it/s]\n",
      "                   all       1513      10350      0.796      0.767      0.827      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50       6.1G     0.9615     0.6868      1.009          9       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.35it/s]\n",
      "                   all       1513      10350      0.769      0.788      0.822      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/50       6.1G     0.9479     0.6826      1.003         14       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.28it/s]\n",
      "                   all       1513      10350      0.802      0.772      0.825      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50       6.1G     0.9458     0.6737      1.002          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.37it/s]\n",
      "                   all       1513      10350      0.798      0.776      0.827      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50       6.1G     0.9352     0.6614     0.9973         15       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350      0.808      0.787       0.83      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50       6.1G     0.9193     0.6504     0.9911          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.34it/s]\n",
      "                   all       1513      10350      0.804       0.78      0.837      0.594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50       6.1G     0.9237     0.6528     0.9909         24       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.25it/s]\n",
      "                   all       1513      10350      0.813      0.795      0.847      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50       6.1G     0.9153     0.6434     0.9881          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.22it/s]\n",
      "                   all       1513      10350      0.803      0.805      0.844        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50       6.1G     0.9117     0.6393     0.9837         20       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.39it/s]\n",
      "                   all       1513      10350      0.837       0.78      0.841      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50       6.1G     0.9052     0.6351     0.9852         17       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350       0.83        0.8      0.852      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50       6.1G     0.8957      0.624     0.9794          8       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.22it/s]\n",
      "                   all       1513      10350      0.834      0.791      0.853      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50       6.1G     0.8944      0.627     0.9773         19       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.34it/s]\n",
      "                   all       1513      10350      0.836      0.794      0.857      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50       6.1G     0.8848     0.6108     0.9751         23       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350       0.85      0.791      0.857      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50       6.1G     0.8796     0.6071     0.9726          6       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.23it/s]\n",
      "                   all       1513      10350      0.851      0.797      0.856      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50       6.1G     0.8695     0.6014     0.9673         30       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:14<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.37it/s]\n",
      "                   all       1513      10350      0.824      0.812      0.862      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50       6.1G      0.863     0.5959     0.9662          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:16<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.18it/s]\n",
      "                   all       1513      10350      0.857      0.805      0.868      0.631\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50       6.1G     0.8702     0.5895     0.9652          9       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.27it/s]\n",
      "                   all       1513      10350       0.84      0.811       0.86      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50       6.1G     0.8579     0.5801     0.9607          2       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:05<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.37it/s]\n",
      "                   all       1513      10350      0.828      0.797      0.854      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50       6.1G     0.8491     0.5719     0.9569          5       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.23it/s]\n",
      "                   all       1513      10350      0.818      0.811      0.859      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50       6.1G     0.8365     0.5613      0.951         12       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350      0.847      0.808       0.86      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50       6.1G     0.8295     0.5553     0.9507          5       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.29it/s]\n",
      "                   all       1513      10350      0.845      0.818      0.867      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50       6.1G     0.8229     0.5488     0.9431         15       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:05<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:12<00:00,  7.32it/s]\n",
      "                   all       1513      10350      0.868        0.8      0.862      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50       6.1G      0.816     0.5424     0.9423          7       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:06<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.24it/s]\n",
      "                   all       1513      10350      0.866      0.811       0.87      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50       6.1G     0.8074     0.5373     0.9395          6       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350      0.835      0.828       0.87      0.644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50       6.1G     0.7985     0.5311     0.9372          6       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:13<00:00,  7.30it/s]\n",
      "                   all       1513      10350      0.864      0.816      0.873      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50       6.1G     0.7893     0.5215     0.9323          5       1248: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 665/665 [04:04<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:15<00:00,  6.21it/s]\n",
      "                   all       1513      10350      0.856      0.822      0.871      0.646\n",
      "\n",
      "50 epochs completed in 3.690 hours.\n",
      "Optimizer stripped from runs/detect/yolov8n_custom15/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/yolov8n_custom15/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/yolov8n_custom15/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "Model summary (fused): 168 layers, 3007403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:14<00:00,  6.73it/s]\n",
      "                   all       1513      10350      0.863      0.816      0.873      0.648\n",
      "               Cyclist       1513        341      0.913      0.815      0.891      0.617\n",
      "              DontCare       1513       2252      0.635      0.315      0.412      0.158\n",
      "                  Misc       1513        216       0.88       0.87       0.93      0.696\n",
      "        Person_sitting       1513         42      0.802      0.833      0.894      0.588\n",
      "                  Tram       1513         95      0.867      0.958      0.973      0.794\n",
      "                 Truck       1513        225       0.94       0.96      0.979      0.847\n",
      "                   Van       1513        581      0.931      0.924      0.963      0.798\n",
      "                   car       1513       5667      0.942      0.947      0.979      0.833\n",
      "                person       1513        931       0.86      0.724       0.84      0.497\n",
      "Speed: 0.4ms pre-process, 3.6ms inference, 0.0ms loss, 0.6ms post-process per image\n",
      "Results saved to \u001b[1mruns/detect/yolov8n_custom15\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-16 22:58:37,364 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/YOLOv8/yolov8n_custom.40d6ded8fdf64ee6b1c5320e391c8443/models/best.pt\n",
      "2023-03-16 22:58:41,756 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/YOLOv8/yolov8n_custom.40d6ded8fdf64ee6b1c5320e391c8443/models/best.pt\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    " \n",
    "# Training.\n",
    "results = model.train(\n",
    "   data='data.yaml',\n",
    "   imgsz=1244,\n",
    "   epochs=50,\n",
    "   batch=8,\n",
    "   name='yolov8n_custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "    handler._at_fork_reinit()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    self.lock._at_fork_reinit()\n",
      "AttributeError: 'NoneType' object has no attribute '_at_fork_reinit'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "Model summary (fused): 168 layers, 3007403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aya/Kitti-ObjectDetection/kitty/valid/labels.cache... 1513 i\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all       1513      10350      0.863      0.817      0.874      0.648\n",
      "               Cyclist       1513        341      0.907      0.815       0.89      0.616\n",
      "              DontCare       1513       2252      0.638      0.314      0.413      0.158\n",
      "                  Misc       1513        216      0.882       0.87       0.93      0.699\n",
      "        Person_sitting       1513         42      0.801      0.833      0.895      0.588\n",
      "                  Tram       1513         95      0.867      0.958      0.971      0.794\n",
      "                 Truck       1513        225      0.941       0.96      0.979      0.846\n",
      "                   Van       1513        581      0.931      0.924      0.963      0.801\n",
      "                   car       1513       5667      0.942      0.946      0.979      0.834\n",
      "                person       1513        931      0.862      0.727      0.844      0.495\n",
      "Speed: 0.5ms pre-process, 2.8ms inference, 0.0ms loss, 0.7ms post-process per image\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=val model=yolov8n_costum.pt data=data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/aya/Kitti-ObjectDetection/kitty/valid/labels.cache... 1513 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1513/1513 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/190 [00:00<?, ?it/s]Exception ignored in: <function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "<function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "    handler._at_fork_reinit()Exception ignored in: Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "<function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    handler._at_fork_reinit()    \n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "self.lock._at_fork_reinit()  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "\n",
      "<function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>AttributeError\n",
      "        : self.lock._at_fork_reinit()handler._at_fork_reinit()'NoneType' object has no attribute '_at_fork_reinit'\n",
      "\n",
      "\n",
      "Exception ignored in: AttributeErrorTraceback (most recent call last):\n",
      ":   File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "<function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>'NoneType' object has no attribute '_at_fork_reinit'\n",
      "\n",
      "        handler._at_fork_reinit()self.lock._at_fork_reinit()\n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "AttributeError<function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>    : \n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "self.lock._at_fork_reinit()'NoneType' object has no attribute '_at_fork_reinit'\n",
      "    \n",
      "AttributeErrorhandler._at_fork_reinit()Traceback (most recent call last):\n",
      ": \n",
      "'NoneType' object has no attribute '_at_fork_reinit'  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    \n",
      "    self.lock._at_fork_reinit()handler._at_fork_reinit()\n",
      "\n",
      "AttributeError  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      ":     'NoneType' object has no attribute '_at_fork_reinit'self.lock._at_fork_reinit()\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute '_at_fork_reinit'\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 190/190 [00:14<00:00, 13.16it/s]\n",
      "                   all       1513      10350      0.863      0.817      0.874      0.648\n",
      "               Cyclist       1513        341      0.907      0.815       0.89      0.616\n",
      "              DontCare       1513       2252      0.638      0.314      0.413      0.158\n",
      "                  Misc       1513        216      0.882       0.87       0.93      0.699\n",
      "        Person_sitting       1513         42      0.801      0.833      0.895      0.588\n",
      "                  Tram       1513         95      0.867      0.958      0.971      0.794\n",
      "                 Truck       1513        225      0.941       0.96      0.979      0.846\n",
      "                   Van       1513        581      0.931      0.924      0.963      0.801\n",
      "                   car       1513       5667      0.942      0.946      0.979      0.834\n",
      "                person       1513        931      0.862      0.727      0.844      0.495\n",
      "Speed: 0.4ms pre-process, 3.4ms inference, 0.0ms loss, 0.7ms post-process per image\n"
     ]
    }
   ],
   "source": [
    "#!yolo task=detect mode=val model=\"/runs/detect/yolov8n_custom6/weights/best.pt\" data=data.yaml\n",
    "results = model.val()  # evaluate model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "    handler._at_fork_reinit()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    self.lock._at_fork_reinit()\n",
      "AttributeError: 'NoneType' object has no attribute '_at_fork_reinit'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "image 1/1 /home/aya/Kitti-ObjectDetection/kitty/train/images/000036_png.rf.04ff80c138765044b69cb8df5d4078f4.jpg: 224x640 5 cars, 1 traffic light, 10.3ms\n",
      "Speed: 0.3ms pre-process, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Before yolo\n",
    "!yolo task=detect mode=predict model=yolov8n.pt source=\"kitty/train/images/000036_png.rf.04ff80c138765044b69cb8df5d4078f4.jpg\" save=True conf=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "    handler._at_fork_reinit()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    self.lock._at_fork_reinit()\n",
      "AttributeError: 'NoneType' object has no attribute '_at_fork_reinit'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11169MiB)\n",
      "Model summary (fused): 168 layers, 3007403 parameters, 0 gradients, 8.1 GFLOPs\n",
      "image 1/1 /home/aya/Kitti-ObjectDetection/kitty/train/images/000036_png.rf.04ff80c138765044b69cb8df5d4078f4.jpg: 384x1248 7 cars, 9.1ms\n",
      "Speed: 0.5ms pre-process, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 1248, 1248)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Try yolov8 on images\n",
    "!yolo task=detect mode=predict model=yolov8n_costum.pt source=\"kitty/train/images/000036_png.rf.04ff80c138765044b69cb8df5d4078f4.jpg\" save=True conf=0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Apply Adversarial Attacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _after_at_fork_child_reinit_locks at 0x7fa87bb39ab0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 256, in _after_at_fork_child_reinit_locks\n",
      "    handler._at_fork_reinit()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 910, in _at_fork_reinit\n",
      "    self.lock._at_fork_reinit()\n",
      "AttributeError: 'NoneType' object has no attribute '_at_fork_reinit'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: adversarial-robustness-toolbox in /home/aya/.local/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: tqdm in /home/aya/.local/lib/python3.10/site-packages (from adversarial-robustness-toolbox) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/aya/.local/lib/python3.10/site-packages (from adversarial-robustness-toolbox) (1.24.2)\n",
      "Requirement already satisfied: scikit-learn<1.2.0,>=0.22.2 in /home/aya/.local/lib/python3.10/site-packages (from adversarial-robustness-toolbox) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /home/aya/.local/lib/python3.10/site-packages (from adversarial-robustness-toolbox) (67.6.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/aya/.local/lib/python3.10/site-packages (from adversarial-robustness-toolbox) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/aya/.local/lib/python3.10/site-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/aya/.local/lib/python3.10/site-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n_costum.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read images and annotations\n",
    "images = [os.path.join('/home/aya/Kitti-ObjectDetection/KITTI-original/2D-objects/letf/training/image_2', x) for x in os.listdir('/home/aya/Kitti-ObjectDetection/KITTI-original/2D-objects/letf/training/image_2')]\n",
    "annotations = [os.path.join('/home/aya/Kitti-ObjectDetection/KITTI-original/2D-objects/letf/training/label_2', x) for x in os.listdir('/home/aya/Kitti-ObjectDetection/KITTI-original/2D-objects/letf/training/label_2') if x[-3:] == \"txt\"]\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Split the dataset into train-valid-test splits \n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n",
    "val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'YOLO' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Define the loss function and the optimizer\u001b[39;00m\n\u001b[1;32m      3\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 4\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'YOLO' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "#Define the loss function and the optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DetectionTrainer' from 'ultralytics.yolo' (/home/aya/.local/lib/python3.10/site-packages/ultralytics/yolo/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39multralytics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39myolo\u001b[39;00m \u001b[39mimport\u001b[39;00m v8\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39multralytics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39myolo\u001b[39;00m \u001b[39mimport\u001b[39;00m DetectionTrainer, DetectionValidator, DetectionPredictor\n\u001b[1;32m      4\u001b[0m \u001b[39m# trainer\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trainer \u001b[39m=\u001b[39m DetectionTrainer(overrides\u001b[39m=\u001b[39m{})\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DetectionTrainer' from 'ultralytics.yolo' (/home/aya/.local/lib/python3.10/site-packages/ultralytics/yolo/__init__.py)"
     ]
    }
   ],
   "source": [
    "from ultralytics.yolo import v8\n",
    "from ultralytics.yolo import DetectionTrainer, DetectionValidator, DetectionPredictor\n",
    "\n",
    "# trainer\n",
    "trainer = DetectionTrainer(overrides={})\n",
    "trainer.train()\n",
    "trained_model = trainer.best\n",
    "\n",
    "# Validator\n",
    "val = DetectionValidator(args=...)\n",
    "val(model=trained_model)\n",
    "\n",
    "# predictor\n",
    "pred = DetectionPredictor(overrides={})\n",
    "pred(source=img, model=trained_model)\n",
    "\n",
    "# resume from last weight\n",
    "overrides[\"resume\"] = trainer.last\n",
    "trainer = detect.DetectionTrainer(overrides=overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image\n",
    "img = Image.open(\"kitty/train/images/000211_png.rf.1efaf37cf5a3f769e76339e2dc48c74f.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def build_optimizer(model, name='Adam', lr=0.001, momentum=0.9, decay=1e-5):\n",
    "    \"\"\"\n",
    "    Builds an optimizer with the specified parameters and parameter groups.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): model to optimize\n",
    "        name (str): name of the optimizer to use\n",
    "        lr (float): learning rate\n",
    "        momentum (float): momentum\n",
    "        decay (float): weight decay\n",
    "\n",
    "    Returns:\n",
    "        optimizer (torch.optim.Optimizer): the built optimizer\n",
    "    \"\"\"\n",
    "    g = [], [], []  # optimizer parameter groups\n",
    "    bn = tuple(v for k, v in nn.__dict__.items() if 'Norm' in k)  # normalization layers, i.e. BatchNorm2d()\n",
    "    for v in model.modules():\n",
    "        if hasattr(v, 'bias') and isinstance(v.bias, nn.Parameter):  # bias (no decay)\n",
    "            g[2].append(v.bias)\n",
    "        if isinstance(v, bn):  # weight (no decay)\n",
    "            g[1].append(v.weight)\n",
    "        elif hasattr(v, 'weight') and isinstance(v.weight, nn.Parameter):  # weight (with decay)\n",
    "            g[0].append(v.weight)\n",
    "\n",
    "    if name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(g[2], lr=lr, betas=(momentum, 0.999))  # adjust beta1 to momentum\n",
    "    elif name == 'AdamW':\n",
    "        optimizer = torch.optim.AdamW(g[2], lr=lr, betas=(momentum, 0.999), weight_decay=0.0)\n",
    "    elif name == 'RMSProp':\n",
    "        optimizer = torch.optim.RMSprop(g[2], lr=lr, momentum=momentum)\n",
    "    elif name == 'SGD':\n",
    "        optimizer = torch.optim.SGD(g[2], lr=lr, momentum=momentum, nesterov=True)\n",
    "    else:\n",
    "        raise NotImplementedError(f'Optimizer {name} not implemented.')\n",
    "\n",
    "    optimizer.add_param_group({'params': g[0], 'weight_decay': decay})  # add g0 with weight_decay\n",
    "    optimizer.add_param_group({'params': g[1], 'weight_decay': 0.0})  # add g1 (BatchNorm2d weights)\n",
    "    LOGGER.info(f\"{colorstr('optimizer:')} {type(optimizer).__name__}(lr={lr}) with parameter groups \"\n",
    "                f'{len(g[1])} weight(decay=0.0), {len(g[0])} weight(decay={decay}), {len(g[2])} bias')\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'YOLO' object has no attribute 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# model.load(state_dict)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[39m#Define the loss function and the optimizer\u001b[39;00m\n\u001b[1;32m      7\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 8\u001b[0m optimizer \u001b[39m=\u001b[39m build_optimizer(model, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mAdam\u001b[39;49m\u001b[39m'\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, momentum\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m, decay\u001b[39m=\u001b[39;49m\u001b[39m1e-05\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[120], line 18\u001b[0m, in \u001b[0;36mbuild_optimizer\u001b[0;34m(model, name, lr, momentum, decay)\u001b[0m\n\u001b[1;32m     16\u001b[0m g \u001b[39m=\u001b[39m [], [], []  \u001b[39m# optimizer parameter groups\u001b[39;00m\n\u001b[1;32m     17\u001b[0m bn \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m nn\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mNorm\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m k)  \u001b[39m# normalization layers, i.e. BatchNorm2d()\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39;49mmodules():\n\u001b[1;32m     19\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(v, \u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(v\u001b[39m.\u001b[39mbias, nn\u001b[39m.\u001b[39mParameter):  \u001b[39m# bias (no decay)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         g[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mappend(v\u001b[39m.\u001b[39mbias)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'YOLO' object has no attribute 'modules'"
     ]
    }
   ],
   "source": [
    "# load pre-trained weights into the model\n",
    "state_dict = torch.load('yolov8n_costum.pt')\n",
    "# model.load(state_dict)\n",
    "\n",
    "#Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = build_optimizer(model, name='Adam', lr=0.001, momentum=0.9, decay=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Step 3: Create the ART classifier\u001b[39;00m\n\u001b[1;32m      3\u001b[0m classifier \u001b[39m=\u001b[39m PyTorchClassifier(\n\u001b[1;32m      4\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      5\u001b[0m     loss\u001b[39m=\u001b[39mcriterion,\n\u001b[0;32m----> 6\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m      7\u001b[0m     input_shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m),\n\u001b[1;32m      8\u001b[0m     nb_classes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 3: Create the ART classifier\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Step 4: Train the ART classifier\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m classifier\u001b[39m.\u001b[39mfit(train_images, train_annotations, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, nb_epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Step 5: Evaluate the ART classifier on benign test examples\u001b[39;00m\n\u001b[1;32m      7\u001b[0m predictions \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(test_images)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the ART classifier\n",
    "\n",
    "classifier.fit(train_images, train_annotations, batch_size=64, nb_epochs=3)\n",
    "\n",
    "# Step 5: Evaluate the ART classifier on benign test examples\n",
    "\n",
    "predictions = classifier.predict(test_images)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(test_annotations, axis=1)) / len(test_annotations)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
    "\n",
    "# Step 6: Generate adversarial test examples\n",
    "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
    "x_test_adv = attack.generate(x=test_images)\n",
    "\n",
    "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
    "\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(test_annotations, axis=1)) / len(test_annotations)\n",
    "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
